---
categories:
- Mathematics
# - Programming
# - Phase Field
# - Others
tags:
- Linear Algebra
- Note
title: 张量代数笔记 I
description: 线性代数1-线性代数中的概念
date: 2025-10-09T09:03:01+08:00
image: 
math: true
hidden: false
comments: true
draft: true
---

$$
\gdef\Hom{\operatorname{Hom}}
\gdef\End{\operatorname{End}}
\gdef\Mat{\mathcal{M}}
\gdef\diag{\operatorname{diag}}
\gdef\GL{\operatorname{GL}}
\gdef\SL{\operatorname{SL}}
\gdef\O{\operatorname{O}}
\gdef\SO{\operatorname{SO}}
\gdef\tr{\operatorname{tr}}
\gdef\adj{\operatorname{adj}}
\gdef\inv{^{-1}}
\gdef\trans{^{\top}}
\gdef\field#1{\mathbb{#1}}
\gdef\tensor#1{\boldsymbol{#1}}
\gdef\zero{\mathbf{0}}
\gdef\one{\mathbf{1}}
$$

## 前言

由于后面可能需要使用很多力学相关的内容，尤其是连续介质力学，我需要一些张量代数和张量微积分的知识来作为学习力学内容的前置。然而，这两个学科说实话记号十分复杂，到现在也没有一个让我能顺着推下去的内容：

- 有的地方只使用下标，有些地方同时使用上下标；
- 有的地方大量使用爱因斯坦求和约定，有的地方又不怎么用到；
- 有些地方严格区分矩阵，向量和张量，而有些地方一开始就声明前两个东西都是张量的特殊形式；
- 有的地方严格区分张量的分量表示和张量本身，将符号分地很细致，而又有的地方不会进行这么严格的区分……

这些磕磕绊绊的存在实在是让我构建一个属于自己的足够有说服力的理论体系。也因此，我计划从各个书目广泛征集张量代数和张量微积分的内容，并把我理解到的内容记录在这个笔记上。希望以此可以帮助我梳理整个理论知识体系。

不过也正因如此，这个系列也许会充斥着大量个人的 *可能错误的* 理解。如果阅读本文的你发现了这些错误，还望海涵且不吝赐教。谢谢。

下面我们给出一些记号约定：

- 我们约定小写黑体字母，如 $\tensor{u}$，$\tensor{v}$ 为向量/一阶张量，以它们为值的函数们使用希腊字母 $\tensor{\varphi}$，$\tensor{\psi}$ 等，对应的小写普通字母将带着它们对应的上下标来表示其分量；
- 大写黑体字母 $\tensor{T}$，$\tensor{R}$，$\tensor{F}$ 等表示矩阵/二阶张量，以它们为值的函数们则记作 $\tensor{\Phi}$，$\tensor{\Psi}$ 等，其对应普通字母也是和上下标一起表示分量。特别地，我们在符号上不区分矩阵和线性映射，即便线性映射的陪域是向量空间；
- 带有上下标的非黑体的大/小写字母表示的是分量，而带有上下标的黑体字母则是表示某个向量（一般都只用下标）。

作为学习张量的前置，我们这里先回顾线性代数的一些定义和定理。

## 线性空间的基本情况

我们先介绍一个线性空间自己上面都可以定义一些什么东西，它都有哪些内禀属性。

### 线性空间

**线性空间**，又称 **向量空间**，我们很早就已经接触过了，比如我们在物理中经常用到的 $3$ 维线性空间 $\R^3$。直观理解就是线性空间是一个装满了向量的空间，最后这些向量可以被表达为一系列的数字。而如果从纯数学角度来讲，线性空间就是元素们满足 *线性* 的空间。下面我们给出定义。

> [!DEF]{线性空间}
>
> 给定一个数域 $\field{k}$ 和一个集合 $V$，我们给集合 $V$ 定义两个运算，（向量）加法以及数乘（标量乘法）：
>
> $$\begin{align*}
&+\vcentcolon V \times V \to V, \\ &(\tensor{u},\tensor{v})\mapsto \tensor{u}+\tensor{v} \ \  (\forall \tensor{u},\tensor{v} \in V) \\
&\cdot\vcentcolon \field{k} \times V \to V,\\ &(\lambda,\tensor{v}) \mapsto  \lambda \cdot \tensor{v} = \lambda \tensor{v}\ \ (\forall \lambda \in \field{k}, \tensor{v} \in V)
\end{align*}$$
> 
> 当 $V$ 和 $\field{k}$ 满足下面的性质时，我们就称 $V$ 是一个 $\field{k}$ 上的线性空间：
> 
> - 加法存在单位元 $\zero\in V$ 满足 $\zero + \tensor{v} = \tensor{v} + \zero = \tensor{v}$ 对任意的 $\tensor{v} \in V$ 都成立;
> - 任何 $V$ 中元素 $\tensor{v}\in V$ 都在加法下存在一个逆元，记为 $-\tensor{v}$，使得 $\tensor{v} + (-\tensor{v}) = (-\tensor{v})+\tensor{v} = \zero;$
> - 加法满足结合律：对于任意的 $\tensor{u},\tensor{v},\tensor{w}\in V$，有 $(\tensor{u}+\tensor{v})+\tensor{w} = \tensor{u}+(\tensor{v}+\tensor{w});$
> - 加法满足交换律：对任意的 $\tensor{u},\tensor{v}\in V$，有 $\tensor{u}+\tensor{v} = \tensor{v}+\tensor{u};$
> - 数乘存在单位元 $\one \in V$ 满足 $\lambda \one = \one$ 对于任意的 $\lambda \in \field{k}$ 都成立；
> - 数乘在向量加法上可分配：$a\cdot(\tensor{u}+\tensor{v}) = a\cdot \tensor{u} + a\cdot \tensor{v}$ 对于任意的 $a\in \field{k}, \tensor{u},\tensor{v}\in V$ 都成立；
> - 数乘在域加法上也可分配：$(a+b)\cdot \tensor{u} = a\cdot \tensor{u} + b\cdot \tensor{u}$ 对于任意的 $a,b\in \field{k}, \tensor{u}\in V$ 都成立；
> - 数乘和域乘法次序可以交换：$a\cdot(b\cdot \tensor{u}) = (a\times b)\cdot \tensor{u}$ 对于任意的 $a,b\in \field{k}, \tensor{u} \in V$ 都成立。
>
> 我们称 $V$ 中的元素为向量，上面的定义中我们混用了向量加法和标量加法，因为二者定义域完全不同；我们用 $\cdot$ 和 $\times$ 区分向量的标量乘法以及标量在域内的乘法。一般我们不将乘法记号写出。

我们也可以说，向量空间是在阿贝尔群的基础上赋予一个域上的标量乘法后形成的模。

而由于线性空间的 *线性*，我们可以自由数乘线性空间中向量们，再按照喜好加减它们。而如果我们选择合适的一组向量，我们可以把向量空间中的任何元素都表达为这组向量的数乘和加法的组合。我们下面将这个想法描述为数学语言，为此我们先引入线性组合和线性无关的概念。

下文我们始终将大写字母 $V$ 和 $W$ 作为我们要使用的线性空间。如果没有特殊声明，我们讨论的线性空间皆为数域 $\R$ 上的线性空间。

### 线性组合

对一组向量可以做 **线性组合**：给向量们数乘以某一些数字后相加。下面是定义：

> [!DEF]{线性组合}
>
> 设 $\field{k}$ 上的线性空间 $V$，由 $V$ 上的加法和数乘，我们定义 $V$ 的一个含有 $n$ 个元素（向量）的子集 $W$ 的 **线性组合** 为形如 
>
> $$\sum_i^n \lambda_i \tensor{v}_i$$
>
> 的 **有限** 和，其中 $\lambda_i\in \field{k}$ 且 $\tensor{v}_i\in W\subset V$。我们称 $\field{k}$ 中的标量为线性组合的系数。

有了线性组合，我们定义线性相关和线性无关。

### 线性相关与线性无关

线性相关和线性无关描述了一组向量之间的关系，是某种 “独立性” 的检验。

> [!DEF]{线性相关与线性无关}
>
> 对 $\field{k}$ 上的线性空间 $V$ 的一个有 $n$ 个元素的子集 $W$，如果它们的线性组合满足条件：
>
> $$\sum_i^n \lambda_i \tensor{v}_i = \zero \iff \lambda_i = 0 \ \ \forall \tensor{v}_i \in W, 1\leq i \leq n,$$
>
> 则我们称这个子集 $W$ 是线性无关的，否则称其为线性相关的。

另外我们定义线性子空间以及线性张成，以及线性空间的基：

### 线性子空间、线性张成和基

> [!DEF]{线性子空间，线性张成}
>
> 给定线性空间 $V$ 的一个子集 $W$，如果它在原线性空间 $V$ 中定义的加法和数乘下依然满足线性空间的性质，我们就称 $W$ 是 $V$ 的一个线性子空间。
>
> 依旧考虑线性空间 $V$ 的一个子集 $G$，它可以 **线性张成** 或者 **生成** 一个线性子空间 $W$，方法是在 $V$ 的运算定义下对 $G$ 中元素进行线性组合所得到的所有结果。此时我们称 $W$ 是 $G$ 的线性张成，$G$ 是$W$ 的生成集或者张成列表。
>
> 如果一个 $V$ 的子集 $B$ 即能张成 $V$ 又是线性独立的，我们就称集合 $B$ 是 $V$ 的一组 **基**，$B$ 的基数（集合的大小）即为该线性空间的维数。

有了基，我们就可以对线性空间进行更复杂的描述以及操作了。比如，根据基的定义，每个线性空间中的向量都可以被表达为基的线性组合。注意到如果我们给定基且对其进行排序之后，线性组合的结果完全由其线性组合系数确定。我们可以把系数记录为一个数表，沿纵向排列即成为我们熟知的 *列向量*。

一组线性无关的向量如果在添加空间内的任意一个别的向量后都会变得线性相关的的话，则称这组线性无关的向量为该线性空间的极大无关组。极大线性无关组可以成为线性空间的一组基，如果这组基有 $n$ 个向量构成，则我们称这个向量空间是 $n$ 维的。

### 向量的表示

我们以某种确定的顺序对这组基进行排序，在这一组基下我们可以将线性空间中的每一个向量 *唯一地* 表示为一个数表，这个数表有 $n$ 个数字有序地构成，我们称这些数字为向量在第 $i$ 个基（方向）上的分量。后续我们认为所有的基都是经过了排序的。我们把这 $n$ 个数字纵向依次排列，成为列向量；不致引起误会时，我们简称为向量。由此，向量有两重含义：抽象线性空间中的一个元素，或者在线性空间有一组基后的一个纵向排列的数表。我们记 $n$ 维向量空间 $V$ 中的向量 $\tensor{v}\in V$ 第 $i$ 个分量为 $v^i$。

### 内积

我们给向量空间额外定义一个运算：内积。这不是线性空间的内禀属性，但是我们会经常用到它。

> [!DEF]{内积}
>
> 内积（有时根据上下文，也称作点积）是满足下面性质的一个 $\langle\cdot,\cdot\rangle\vcentcolon V\times V\to \field{k}$ 的二元运算：
>
> - 共轭对称：$\langle \tensor{x},\tensor{y}\rangle = \overline{\langle \tensor{y},\tensor{x}\rangle};$
> - 对第一个元素有线性性：$\langle a\tensor{x}+b\tensor{y},\tensor{z}\rangle = a\langle \tensor{x},\tensor{z}\rangle + b\langle \tensor{y},\tensor{z}\rangle;$
> - 非负性：对任意的非 $0$ 元素 $\tensor{x}$，$\langle \tensor{x},\tensor{x}\rangle > 0;$

带有内积的向量空间成为内积空间。由于我们讨论的向量空间在 $\R$ 上，共轭对称退化为单纯的对称。在内积定义后我们可以定义正交：内积为 $0$ 的两个向量是正交的。借助内积我们可以定义向量之间的 *角度* 以及向量的 *长度*。我们以我们熟悉的方式定义内积：$\tensor{v}\cdot\tensor{v'} = \sum_i v_i{v'}_i$。在这样的定义后，我们 **声明** 我们之前定义的这组基是单位正交基，即基中每个向量的长度为 $1$，且彼此正交。

定义了内积的向量空间我们会称之为内积空间。涉及 “正交” 的部分概念是需要内积的参与的。

## 线性映射与矩阵

一个线性空间自身大概就这么一些东西了。要想更深入研究线性空间，就必须将不同的线性空间联系起来。而线性映射由于其特殊性质，可以被写成一个数表，成为矩阵。

### 线性映射

我们引入线性映射，即保持线性空间结构（加法和数乘）的映射。这样的映射不会破坏线性空间的结构：一个线性空间在映射后依旧还是一个线性空间。这样的想法在严格化后成为所谓的线性映射，或者线性同态。

> [!DEF]{线性映射（线性同态）}
>
> 设 $V,W$ 为同一数域 $\field{k}$ 上的线性空间。映射
> 
> $$\tensor{\varphi}\vcentcolon V\to W$$
> 
> 称为线性映射或线性同态，若对任意 $\tensor{u},\tensor{v}\in V$ 与 $\lambda\in\field{k}$，有
> 
> $$\tensor{\varphi}(\tensor{u}+\tensor{v})=\tensor{\varphi}(\tensor{u})+\tensor{\varphi}(\tensor{v}),\qquad \tensor{\varphi}(\lambda \tensor{u})=\lambda \tensor{\varphi}(\tensor{u}).$$
> 
> 等价地，对任意有限和，
> 
> $$\tensor{\varphi}\Bigl(\sum_{i=1}^n \lambda_i v_i\Bigr)=\sum_{i=1}^n \lambda_i \tensor{\varphi}(v_i).$$
> 
> 记全体线性映射为 $\Hom_{\field{k}}(V,W)$ 或 $\mathcal{L}(V,W)$。若 $\tensor{\varphi}$ 为双射且 $\tensor{\varphi}^{-1}$ 亦线性，则称为线性同构。

总的来讲，$V$ 到 $W$ 的线性映射 $\tensor{\varphi}$ 让下面的做法是完全可行的：我们可以直接将 $\tensor{v}\in V$ 映射到 $\tensor{w} = \tensor{\varphi}(v) \in W$，也可以先将 $\tensor{v}$ 变为几个向量 $\tensor{v_i}$ 的线性组合，再把这些向量映射到 $\tensor{w_i} = \tensor{\varphi}(\tensor{v_i}) \in W$ 中，最后再对它们进行线性组合。这两条路径将给出完全相同的结果。我们称从线性空间 $V$ 到其自身的线性映射为 *线性变换* 或者 *线性算子*，$V$ 上全体线性变换记为 $\End(V)$。

直接研究线性映射可能没有那么方便，所幸我们可以转而研究矩阵，利用矩阵便利地研究线性映射。

### 矩阵

矩阵对线性映射的作用就相当于函数的表达式对函数本身的作用一样，有了矩阵就可以知道线性映射具体怎么将一个向量映射到另一个空间中了。在给线性空间选定基后，我们可以把线性映射表达为一个二维数表，称之为 **矩阵**。我们这样确定矩阵中的元素：选定 $V$ 中的第 $j$ 个基，该基在其表示下自然为将若干个 $0$ 和一个 $1$ 纵向排列的数表，其中 $1$ 出现在第 $j$ 个位置上，它在线性映射后得到 $W$ 中的一个向量，该向量在 $W$ 的基下的表示为 $\tensor{w}_j$，我们将 $\tensor{w}_j$ 作为矩阵的第 $j$ 列。

我们设 $V$ 是 $n$ 维的，$W$ 是 $m$ 维的，则 $j$ 的范围为从 $1$ 到 $n$，而 $W$ 中的每个向量都由 $m$ 个数字表示出来，即其列向量有 $m$ 个数字。因此，最后得到的二维数表有 $m$ 行 $n$ 列，我们称之为 $m\times n$ 矩阵。

我们记一个 $m\times n$ 矩阵为 $\tensor{A}$，它是一个由 $n$ 维线性空间到 $m$ 维线性空间的一个线性映射，故其只能作用在 $n$ 维线性空间的元素上。我们记它的第 $i$ 行第 $j$ 列的元素（后成为第 $(i,j)$ 位的元素）为 $A^i{}_j$ 或者 $[\tensor{A}]^i{}_j$，反过来通过元素记号 $B^i{}_j$ 我们记矩阵 $\tensor{B}$ 为 $[B^i{}_j]$。另外，我们可以把向量纵向依次排列得到一个矩阵，若矩阵 $\tensor{C}$ 第 $j$ 列为列向量 $\tensor{c}_j$，我们也将 $\tensor{C}$ 记为 $[\tensor{c}_j]$。

根据这种表示方法，我们自然地给出当向量和线性映射都在基下表示为一维和二维数表时，计算向量在线性映射下的结果的方法：

$$w^i = \sum_j A^i{}_j v^j,$$

其中 $i$ 代表着新向量 $\tensor{w}$ 在 $W$ 空间的基下的第 $i$ 的分量。照此方法，我们可以得到线性映射的复合的矩阵表示计算方法：设 $\tensor{A}$ 为 $m\times p$ 矩阵，$\tensor{B}$ 为 $p\times n$ 矩阵，则它们的复合为一个 $m\times n$ 矩阵，其第 $i$ 行第 $j$ 列（第 $(i,j)$ 位）的元素为：

$$[\tensor{AB}]^i{}_j = \sum_{k}^p A^i{}_k B^k{}_j.$$

我们称上面两个运算分别为矩阵与向量的乘法，以及矩阵乘法。特别地，我们将列向量可以看作 $n\times 1$ 的矩阵，因此上述两个运算可以统一为矩阵乘法运算。

### 转置

矩阵上还可以定义一个特殊运算，称作 *转置*，转置将 $m\times n$ 矩阵变为 $n\times m$ 矩阵，其原矩阵中第 $(i,j)$ 个元素变为新矩阵中第 $(j,i)$ 个元素，这一运算记号上记作

$$\tensor{A^\top} = [A^i{}_j]^\top = [A^j{}_i].$$

### 矩阵空间

我们称 $m$ 维线性空间 $V$ 到 $n$ 维线性空间 $W$ 上的全体线性映射构成一个集合，记为 $\Hom(V,W)$，在选定基后它们的矩阵表示为 $\R^{m\times n}$，$\Mat_{m\times n}(\R)$ 或 $\Mat(m, n)$ 当 $\R$ 的条件已经隐含时。另外如果上述空间有 $m = n$，则我们进一步简记矩阵集合为 $\Mat(n)$。

另外我们还可以给线性映射定义加法：在矩阵表示下为逐点加法。逐点意为两个矩阵它们同位置的数字相加；还可以定义数乘或称标量乘法，计算方法为逐点乘以数字或标量。我们做如下声明：$\Mat(m,n)$ 在上面的加法和数乘下成为线性空间。


最后我们指出所有的 $n$ 维线性空间都同构于 $\R^n$。

## 方阵及一些特殊方阵

下面我们介绍一类特殊的矩阵，它们具有更多特殊的性质，我们也可以给他们定义更多的特殊结构。

### 方阵

我们考虑由 $n$ 维向量空间到 $n$ 维向量空间的线性映射在它们各自基下的表示，即 $n\times n$ 型矩阵。由于它们的行数和列数相等，我们称它们为 $n$ 阶方阵。在不至于引起误会时，我们仍然称它们为矩阵。对于任意两个 $n$ 阶方阵，根据矩阵乘法的规则，它们可以自由地相乘，得到新的 $n$ 阶方阵。

作为线性映射，矩阵在满足一定条件时可以有逆矩阵来作为线性映射的逆映射的表示方法。该条件可以简化为 **行列式** 不为 $0$。

### 行列式

> [!DEF]{行列式}
>
> 行列式是一个 $\det \vcentcolon \Mat(n) = \R^{n\times n} \to \R$ 的映射，其由下列性质唯一确定：
>
> - 单位阵 $\tensor{I}$ 的行列式为 $1$
> - 行列式是多线性的：如果行列式的一行/一列可以写为线性组合的形式，则行列式本身就可以拆分为两者的线性组合形式。
> - 行列式是交错的：如果行列式中某两行/两列相等，则行列式为 $0$。

行列式有这样一些性质：转置不影响行列式结果；方阵乘法次序不影响行列式结果；可以先计算方阵行列式后乘起来，结果和先进行矩阵乘法后取行列式相同。行列式有所谓的多线性性，对每行每列都是线性的。为计算逆矩阵，我们需要行列式的同时需要 **伴随矩阵**：

### 伴随矩阵和逆矩阵

> [!DEF]{伴随矩阵}
>
> 方阵 $\tensor{A}$ 的伴随矩阵记为 $\adj(\tensor{A})$，其定义为满足 $\adj(\tensor{A}) \tensor{A} = \det(\tensor{A}) \tensor{I}$

矩阵的伴随和矩阵的乘法可以交换次序，结果为行列式乘以单位阵。这里数乘按照我们已经给出的矩阵数乘方法（即逐点乘法）。请注意虽然伴随矩阵的记号是普通小写字母，其结果仍然是和 $n$ 阶方阵 $\tensor{A}$ 同样形状的一个 $n\times n$ 矩阵（方阵）。

通过伴随矩阵，我们给行列式非零的矩阵定义 **逆矩阵**：

> [!DEF]{逆矩阵}
>
> 方阵 $\tensor{A}$ 若行列式不为 $0$，则我们定义其逆矩阵为 $\tensor{A}\inv = \frac{1}{\det(A)}\adj(\tensor{A})$

逆矩阵在线性映射意义下为原映射的逆映射。我们称行列式不为 $0$ 的方阵为可逆矩阵。全体 $n$ 阶可逆矩阵我们记作 $\GL_n(\R)$， $\GL(n,R)$，在 $\R$ 自明时记为 $\GL(n)$。

可逆矩阵有丰富的性质。我们给出 *相似*、*合同*、*等价* 三种矩阵之间的关系。它们都和可你矩阵有一定的联系。

## 相似，相似对角化，特征值与特征向量，合同，正交矩阵，等价

### 矩阵相似

> [!DEF]{矩阵相似}
>
> 矩阵 $\tensor{A},\tensor{B}\in\Mat(n)$ 相似当且仅当存在方阵 $P\in\GL(n)$ 使得
>
> $$\tensor{A = P\inv BP}.$$

相似矩阵表示同一个线性变换（从线性空间到自身的线性映射）的在选择不同的基后的不同表示。其保持特征值、行列式、迹、秩、特征多项式等不变。下文介绍矩阵的迹和特征多项式，这里不介绍秩。

### 相似对角化

由矩阵相似可以得到 **相似对角化**，即使用可逆矩阵 $\tensor{P}$ 让矩阵 $\tensor{A}$ 成为对角阵。对角阵即只有对角元素不为 $0$ 的方阵，有时记为 $\diag(a_1,\dots,a_n)$，其中 $a_i$ 为该对角阵第 $(i,i)$ 个元素。

对矩阵 $\tensor{A}$ 进行相似对角化得到的 $\tensor{P}$ 与 $\tensor{\Lambda}$，我们称 $\tensor{P}$ 中的第 $j$ 列为 矩阵 $\tensor{A}$ 的第 $j$ 个 **特征向量**，对应的 $\tensor{\Lambda}$ 中的第 $(j,j)$ 个元素称为矩阵 $\tensor{A}$ 的第 $j$ 个 **特征值**，或第 $j$ 个特征向量对应的特征值。对角阵 $\tensor{\Lambda}$ 的行列式即为 $\tensor{A}$ 的行列式。

### 特征值与特征向量

特征值与特征向量同时也可以用下面的方式定义：

> [!DEF]{矩阵特征值与特征向量}
>
> 矩阵 $\tensor{A}$ 和向量 $\tensor{x}$ 若满足下列关系：
>
> $$\tensor{Ax} = \lambda\tensor{x},$$
>
> 其中 $\lambda$ 是一个数，则称 $\tensor{x}$ 是 $\tensor{A}$ 的特征向量，$\lambda$ 为该特征向量对应的特征值。

可以通过行列式 $\det(\tensor{Ax}-\lambda \tensor{x}) = 0$ 计算特征值并得到特征向量，其展开的多项式即为所谓 **特征多项式**。

另外我们介绍不太常用的关系：矩阵合同以及矩阵等价。

### 矩阵合同

> [!DEF]{矩阵合同}
>
> 矩阵 $\tensor{A},\tensor{B}\in\Mat(n)$ 合同当且仅当存在方阵 $P\in\GL(n)$ 使得
>
> $$\tensor{A = P\trans BP}.$$

合同矩阵表示同一个二次型在不同基下的描述，保持矩阵秩不变、对称性不变、惯性指数（正负特征值的个数）不变。

### 正交矩阵

我们指出有这样一类特殊矩阵称为 **正交矩阵**：

> [!DEF]{正交矩阵}
>
> 若矩阵 $\tensor{A}$ 满足 $\tensor{AA}\trans = \tensor{I}$，即 $\tensor{A}\inv = \tensor{A}\trans$，则称 $\tensor{A}$ 是正交矩阵。 

使用正交矩阵进行的合同和相似操作是相等的。全体 $n$ 维正交矩阵的集合记作 $\operatorname{O}(n)$，正交矩阵的行列式一定为 $1$ 或 $-1$；更进一步，全体 行列式为 $1$ 的 $n$ 维正交矩阵组成的集合记作 $\SO(n)$。

### 矩阵等价

最后是矩阵等价：

> [!DEF]{矩阵等价}
>
> 矩阵 $\tensor{A},\tensor{B}\in\Mat(m,n)$ 等价当且仅当存在方阵 $P\in\GL(m),Q\in\GL(n)$ 使得
>
> $$\tensor{A = P B Q}.$$

矩阵等价表示两个矩阵为同一个线性映射在不同基下的不同表示，可以通过初等变换得到另一个。等价保持秩不变。

## 迹，矩阵不变量

### 矩阵的迹

行列式实则为一个矩阵函数，除了这一特殊矩阵函数外，常用的矩阵函数还有 **迹**。

> [!DEF]{迹}
>
> 迹定义为方阵的对角元素相加之和。即 $$\tr(\tensor{A}) = \sum_{i} A^i{}_i.$$

迹有这样一些性质：交换矩阵乘法次序不改变迹的结果；迹具有（单）线性性；转置不影响矩阵的迹；矩阵相似不改变矩阵的迹。

### 三阶矩阵不变量

最后我们介绍三阶方阵三个不变量，后面会大量用到：

> [!DEF]{三阶方阵的不变量}
>
> 三阶方阵的第一不变量为：
>
> $$I_1 = \tr(\tensor{A});$$
>
> 第二不变量为：
> 
> $$\frac 12 ((\tr(\tensor{A}))^2 - tr(\tensor{A}^2));$$
>
> 第三不变量为：
>
> $$I_3 = \det(\tensor{A}).$$

且三阶方阵的迹和行列式有特殊的关系：

> [!REM]{三阶方阵迹与行列式的关系}
>
> 三阶方阵的迹和行列式满足下列关系：
> $$\det(\tensor{A}) = \frac 16(\tr(\tensor{A})^3 - 3\tr(\tensor{A})\tr(\tensor{A}^2) + 2\tr(\tensor{A}^3))$$

三个不变量的 “不变” 指在坐标变换的意义下不变。

## 小结

我们这里对本节内容做一个小结。我们做了下面这些事：

- 定义什么是向量空间，考虑了向量空间的一些基本运算和基本性质，如线性组合、线性无关、线性相关、子空间、线性张成等；
- 得到了线性空间的基，线性空间的所有向量都可以在基下表达为基的线性组合，据此向量可以表达为一个数表；
- 向量空间可以定义内积，两个向量的内积给出一个 $\field{k}$ 上的一个数，这允许我们定义正交；
- 两个向量空间之间可以定义线性映射，线性映射要保留线性空间的加法和数乘；
- 在给线性空间都选择好基之后，线性映射可以表达为一个二维数表，称为矩阵。从 $n$ 维线性空间到 $m$ 维线性空间的线性映射可以表达为 $m\times n$ 型矩阵；
- 矩阵第 $j$ 列的意义则是原空间第 $j$ 个基向量在映射到新空间后的表示。矩阵第 $(i,j)$ 个元素的意义，是原空间中第 $j$ 个基向量在新空间中的表示下第 $i$ 个分量；
- 求向量在线性映射下的结果可以归结为矩阵与向量的乘法；求线性映射的复合可以归结为矩阵与矩阵的乘法；
- 单独考虑矩阵，其上可以定义转置运算，将行与列进行交换；全体 $m\times n$ 型矩阵可以形成一个 $mn$ 维线性空间。
- 方阵可以表达两个 $n$ 维线性空间之间的线性映射。方阵上可以定义行列式，行列式不为 $0$ 的矩阵则是可逆矩阵，代表线性映射可逆。
- 借助可逆矩阵，可以定义矩阵的相似、合同、等价等关系，由相似可以引出对角化，进一步得到特征值与特征向量
- 方阵上可以定义矩阵的迹，相似矩阵具有相同的迹；三阶方阵上有三个不变量，分别为矩阵的迹（一阶矩），迹的平方减去平方的迹再除以2（二阶矩，二阶方阵的行列式计算方法），矩阵的行列式（三阶矩）。